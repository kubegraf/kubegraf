# View: `inferenceservices`

- **Route file**: `ui/solid/src/routes/InferenceServices.tsx`
- **Component closure**: 7 files (TS/TSX). Controls extracted from 3 TSX files.

## Headings & copy

- `CPU`
- `Deploy Model Inference Service`
- `Deploy and manage ML model inference services`
- `Environment Variables`
- `GPU`
- `Host`
- `Inference Services`
- `Input JSON`
- `Max Replicas`
- `Memory`
- `Metrics visualization coming soon`
- `Min Replicas`
- `Model File * (.pt, .onnx, .pickle, .h5)`
- `Model Storage`
- `Namespace`
- `Namespace:`
- `No inference services found`
- `Path`
- `Replicas`
- `Response`
- `Runtime *`
- `Selected: ( KB)`
- `Service Name *`
- `Target CPU %`

## Buttons

- `+ Add`
- `+ Deploy Model`
- `Cancel`
- `Delete`
- `Deploy Service`
- `Deploy Your First Model`
- `Deploying...`
- `Loading...`
- `Logs`
- `Metrics`
- `Overview`
- `Refresh`
- `Refresh Logs`
- `Send Test Request`
- `Test Interface`
- `Testing...`
- `View`
- `×`

## Component prop text (cards/widgets)

### `placeholder=`
- `2Gi`
- `KEY`
- `PVC Name (optional)`
- `inference.example.com`
- `my-inference-service`
- `value`

## Controls by file

### `features/inference/InferenceServiceForm.tsx`
- **headings/copy**: `CPU`, `Deploy Model Inference Service`, `Environment Variables`, `GPU`, `Host`, `Max Replicas`, `Memory`, `Min Replicas`, `Model File * (.pt, .onnx, .pickle, .h5)`, `Model Storage`, `Namespace`, `Path`, `Replicas`, `Runtime *`, `Selected: ( KB)`, `Service Name *`, `Target CPU %`
- **buttons**: `+ Add`, `Cancel`, `Deploy Service`, `Deploying...`, `×`
- **jsx props**:
  - `placeholder=`: `2Gi`, `KEY`, `PVC Name (optional)`, `inference.example.com`, `my-inference-service`, `value`

### `features/inference/InferenceServicePanel.tsx`
- **headings/copy**: `Input JSON`, `Metrics visualization coming soon`, `Namespace:`, `Response`
- **buttons**: `Loading...`, `Logs`, `Metrics`, `Overview`, `Refresh`, `Refresh Logs`, `Send Test Request`, `Test Interface`, `Testing...`

### `features/inference/InferenceServicesList.tsx`
- **headings/copy**: `Deploy and manage ML model inference services`, `Inference Services`, `No inference services found`
- **buttons**: `+ Deploy Model`, `Delete`, `Deploy Your First Model`, `View`
